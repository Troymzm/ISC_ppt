尊敬的各位评委老师们，大家上午好！非常荣幸今天能在这里向大家介绍我们的作品——LiteGuard，一个基于高效单帧图像与时序残差分析的轻量级深度伪造检测APP。我会从以下几个方面来介绍我们的作品：包括背景介绍、系统架构、作品实现、核心优势、作品创新点以及作品的展示。

首先，我们来回顾一下深度伪造技术的发展历程。早期，随着图像处理技术与计算机图形学技术的发展，电影中开始出现面部融合特效，虽然这与深度伪造的自动化程度相去甚远，但为后续的面部替换奠定了概念基础。2017年末，一位名为“deepfakes”的Reddit用户开始发布利用深度学习算法合成的名人换脸色情视频，使得“Deepfake”（深度伪造）这一术语迅速进入公众视野。这些早期作品主要基于自编码器技术，通过学习源面部特征并映射到目标面部，实现面部替换。在此之后，各种开源深度伪造工具如DeepFaceLab、FaceSwap等相继出现，使得深度伪造技术的门槛大幅降低，普通用户也能轻松制作高质量的深度伪造内容。随着深度学习技术的发展，尤其是生成对抗网络（GANs）的广泛应用，深度伪造技术得到了进一步的提升。如今，深度伪造不仅限于面部替换，还扩展到语音合成、全身动作捕捉等多个领域。然而，深度伪造技术的普及使得个人隐私和信息安全面临严重威胁。伪造的图像和视频可以被用于恶意传播、诈骗、网络暴力等行为，对个人和社会造成严重影响。此外，深度伪造技术的滥用还可能导致公众对媒体内容的信任危机，影响社会舆论和公共安全。

面对深度伪造技术带来的诸多挑战，深度伪造检测技术应运而生。现有的深度伪造检测方法主要分为图像级检测和视频级检测两种。图像级检测方法主要侧重于分析单张深度伪造图像中存在的空间域伪影，这些伪影是深度伪造模型在生成或篡改图像时留下的痕迹，包括但不限于局部区域之间不自然的差异、像素级别的异常模式，以及在频域中可能出现的特定网格结构或重复性纹理。常见的图像级检测方法，例如面部X射线（Face X-ray）、自混合图像（SBIs）、F3-Net频域检测和GAN指纹分析等，它们虽然在特定伪造方法上表现良好，但缺点是过度依赖特定伪造方法，导致跨库泛化性较差 。由于深度伪造视频往往是通过逐帧生成或篡改图像并简单拼接而成，这可能导致视频在时间维度上出现不连贯或不自然的跳变，而视频级检测方法则着眼于捕捉深度伪造视频中的这种时间不一致性。常见的视频级检测方法，如循环神经网络（RNNs）、Transformer模型、结合注意力机制的时空一致性检测以及眼球运动与眨眼模式分析等，虽然在一定程度上能够提高模型的泛化能力，但它们普遍存在计算开销大、无法满足轻量化需求的缺点，而我们的LiteGuard正是为了解决这些问题而设计的。

接下来，我将为大家介绍LiteGuard的系统架构。我们的APP主要分为Flutter层和Android层两部分。Flutter层主要负责用户界面模块、状态管理模块和通信模块，它处理用户的输入并显示检测结果。Android层是核心的检测部分，包含预处理模块、图片检测模块和视频检测模块。当用户输入图片时，预处理模块会进行图片输入和人脸提取。如果用户输入的是视频，则会进行视频帧采样和人脸提取。提取出的人脸数据会作为单帧数据或帧序列数据，分别输入到图片检测模块和视频检测模块。图片检测模块采用基于EfficientFormerV2的单帧图片检测模型，而视频检测模块则采用了基于EfficientnetB0的时序残差分析模型。这两个模型都经过深度伪造检测数据集的训练，以确保其检测的准确性。

LiteGuard的核心优势主要体现在三个方面：模型轻量化、本地化部署、以及强大的泛化能力。

首先是**模型轻量化** 。我们的单帧图片检测模型参数量为1千两百万左右，模型大小仅为47.03 MB。时序残差分析模型的参数量为480万左右，模型大小仅为18.43 MB。与中科院自动化研究所团队开发的开源Deepfake检测模型Deepfake Defenders（模型大小338 MB）相比，LiteGuard的模型尺寸大幅缩小，更适合在计算资源受限的端侧进行部署，并且能够大幅度提高检测速度。LiteGuard的单帧图片检测模型在Android端的推理速度为每秒约2帧，这使得LiteGuard能够在移动设备上实现高效的实时深度伪造检测。

其次是**本地化部署** 。LiteGuard支持本地化部署，用户检测所提供的所有的人脸数据都存储在本地，不会上传至云端，从而有效的保护了用户的人脸隐私安全。这意味着用户无需担心数据泄露的风险。此外，LiteGuard可以实现即时检测，由于无需网络传输，不会带来任何的网络延迟，在视频通话或直播中实现实时低延迟的深度伪造识别。这与Sensity等知名Deepfake检测工具形成鲜明对比，Sensity通常需要将数据上传至云端，并且会受到网络条件的影响以及巨大的服务器计算资源开销。

最后是**强大的泛化能力** 。LiteGuard在各种数据集上均有较高的准确率，域内准确率高，虚警率低。我们的域内AUC高达0.98，虚警率低至0.04。即使当训练集与测试集差别较大时，跨库AUC仍然能够达到0.74。而以Face X-ray为例，该方法跨库AUC仅为0.65，与之相比，我们的泛化性优势非常明显，检测更加精准。

我再来介绍一下LiteGuard的**创新点**。LiteGuard在多个方面都进行了创新。首先，我们采用了通过残差帧捕获时序特征的方法。这种方法能够捕捉到视频中细微的动态不一致性，而且计算复杂度极低，这对于轻量化部署至关重要。其次，我们运用了多样化的数据增强手段 ，包括空间数据增强和时序数据增强，其中空间数据增强包括水平翻转，颜色抖动，高斯模糊等，而时序数据增强则包括随机帧跳跃，帧重复等。这些数据增强手段能够有效地提高模型在面对不同伪造方法和质量时的鲁棒性和泛化能力。再者，我们采用了轻量级预训练模型EfficientFormerV2 ，这为模型的小体积和高效率奠定了基础。最后，我们在数据集方面也进行了创新 。相比于常见的深度伪造数据集FF++与Celeb-DF-v2等相比，我们的数据集不仅具有较高的亚洲人脸样本占比，而且伪造方法多样，伪造质量高，这使得模型的泛化能力得到了进一步的提高。

最后，我们来对LiteGuard进行一个简单的演示。LiteGuard的用户界面设计简洁直观，用户可以选择本地媒体进行分析，检查图像或视频是否存在伪造，也可以开启实时视频监控功能，在视频通话或直播中进行实时低延迟的深度伪造检测。

展示过程。。。

LiteGuard的诞生，旨在为用户提供一个可靠、高效、安全的深度伪造检测解决方案。我们相信，通过LiteGuard，能够有效应对深度伪造技术带来的挑战，保护个人隐私和信息安全。

感谢大家的聆听！谢谢！