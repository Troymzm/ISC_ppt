# 讲稿（20250729周老师汇报用）

> P1 

尊敬的周老师(各位评委老师们)，(大家上午)您好！非常荣幸今天能在这里向(大家)您(介绍)汇报我们的作品——LiteGuard，一个基于高效单帧图像与时序残差分析的轻量级深度伪造检测APP。

> P2

我会从以下几个方面来介绍我们的作品：包括背景介绍、系统架构、作品实现、核心优势、作品创新点以及作品的展示。

> P3 P4

首先，我们来回顾一下深度伪造技术的发展历程。早期，应用于电影中的面部融合特效，为深度伪造奠定了概念基础。2017年末，一位名为“deepfakes”的Reddit用户开始发布利用深度学习算法合成的名人换脸色情视频，使得“Deepfake”（深度伪造）这一术语迅速进入公众视野。在此之后，各种开源深度伪造工具如DeepFaceLab、FaceSwap等相继出现，使得深度伪造技术的门槛大幅降低。随着深度学习技术的发展，尤其是生成对抗网络（GANs）的广泛应用，深度伪造技术得到了进一步的提升。如今，深度伪造不仅限于面部替换，还扩展到语音合成、全身动作捕捉等多个领域。然而，深度伪造的图像和视频可以被用于恶意传播、诈骗、网络暴力等行为，使得个人隐私和信息安全面临严重威胁。

> P5

面对深度伪造技术带来的诸多挑战，深度伪造检测技术应运而生。现有的深度伪造检测方法主要分为图像级检测和视频级检测两种。图像级检测方法主要侧重于分析单张深度伪造图像中存在的空间域伪影。常见的图像级检测方法，例如面部X射线（Face X-ray）、自混合图像（SBIs）、F3-Net频域检测和GAN指纹分析等，但这些方法过度依赖特定伪造方法，导致跨库泛化性较差 。由于深度伪造视频往往在时间维度上会出现不连贯或不自然的跳变，视频级检测方法则着眼于捕捉深度伪造视频中的这种时间不一致性。常见的视频级检测方法，如循环神经网络（RNNs）、Transformer模型、结合注意力机制的时空一致性检测以及眼球运动与眨眼模式分析等，虽然在一定程度上能够提高模型的泛化能力，但它们普遍存在计算开销大、无法满足轻量化需求的缺点。

> P6 P7

接下来，我将为大家介绍LiteGuard的系统架构。我们的APP主要分为Flutter层和Android层两部分。Flutter层主要包括用户界面模块、状态管理模块和通信模块，它处理用户的输入并显示检测结果。Android层是核心的检测部分，包含预处理模块、图片检测模块和视频检测模块。当用户输入图片时，预处理模块会进行图片输入和人脸提取。如果用户输入的是视频，则会进行视频帧采样和人脸提取。提取出的人脸数据会作为单帧数据或帧序列数据，分别输入到图片检测模块和视频检测模块。图片检测模块采用基于EfficientFormerV2的单帧图片检测模型，而视频检测模块则采用了基于EfficientnetB0的时序残差分析模型。这两个模型都是通过深度伪造检测数据集训练得到的。

> P8 P9

我们的LiteGuard的实现部分主要包括三个部分：单帧空间检测、时序残差检测和APP应用的实现。

> P10

帧级空间检测整体上我们采用全监督学习模式，对同一张人脸ID我们有真实的，也有伪造的样本。在模型架构层面，我们依赖EfficientformerV2这个CNN与Attention融合架构的backbone,通过一定的微调，对伪造图像提取伪影上下文与局部细节。其中backbone结合了CNN极强的空间提取能力以及Attention的全局信息相关能力，更有效的捕捉图像级的局部伪影以及边缘融合异常。

为了增强模型的鲁棒性和泛化能力，我们首先对未处理的原图像通过人脸对齐剪裁模块Retinaface，正确识别到人脸并对人脸对进行剪裁对齐，接着对原始图片做了随机的空间数据增强，经过我们后期消融实验对比，数据增强极大提高了库内的精确度，一定程度上提高了跨库的泛化性。

> P11

如图所示为我们的训练结果，在25个epoch之后我们的单帧检测模型库内AUC达到了0.98,准确度达到了0.93，同时具有非常低的误报率。

> P12

接下来，介绍我们的时序残差检测模块实现的核心算法。首先，模型接收帧序列的输入；接着，对相邻两帧转为张量后进行残差计算，通过帧间差分来捕获视频中的时间不一致性；然后，对残差进行展平处理后输入到EfficientNet-B0模型提取残差空间特征；提取的特征再经过全局平均池化；最后，通过一个分类头输出预测结果和置信概率，从而判断视频是否为伪造。

> P13

我们没有使用复杂的时序模型比如 LSTM 或 Transformer，而是采用简单高效的平均策略。这是因为在实际部署场景下，复杂结构会大大提高计算成本。如图所示训练50个epoch的loss曲线和auc曲线。我们可以发现，在没有采用复杂的时序模型的情况下，模型的AUC和准确率依旧较高。

> P14

我们再来简要的介绍一下LiteGuard的APP实现。我们的APP实现主要基于以下三个部分：用户界面与交互的实现，核心检测功能的实现以及模型输出的解析。LiteGuard 的用户界面与交互实现采用了 Flutter 跨平台框架，结合 BLoC 状态管理模式，并通过平台通道与原生 Android 进行深度集成。整个架构分为前端 Flutter 层和后端原生 Android 层，既保证了良好的用户体验，也能充分利用原生系统能力。系统核心检测功能是通过在Android原生层移植模型训练时的预处理， 利用ONNX进行深度学习推理来实现的。在最后的模型输出解析部分，我们将模型检测流程完成后得到的分析报告在主界面上以丰富的可视化方式展现给用户，使用户获得检测结果。

> P15 

再来看一下LiteGuard的核心优势，我们的核心优势主要体现在三个方面：模型轻量化、本地化部署、以及强大的泛化能力。

> P16

首先是模型轻量化 。我们的单帧图片检测模型参数量为1千两百万左右，模型大小仅为47.03 MB。时序残差分析模型的参数量为480万左右，模型大小仅为18.43 MB。与中科院自动化研究所团队开发的开源Deepfake检测模型Deepfake Defenders（模型大小338 MB）相比，LiteGuard的模型尺寸大幅缩小，更适合在计算资源受限的端侧进行部署。

> P17

其次是本地化部署 。LiteGuard支持本地化部署，用户检测所提供的所有的人脸数据都存储在本地，不会上传至云端。这意味着用户无需担心数据泄露的风险。此外，LiteGuard可以实现即时检测，由于无需网络传输，不会带来任何的网络延迟，在视频通话或直播中实现实时低延迟的深度伪造识别。这与Sensity等知名Deepfake检测工具形成鲜明对比，Sensity通常需要将数据上传至云端，并且会受到网络带宽的影响以及巨大的服务器计算资源开销。

> P18

最后是强大的泛化能力 。LiteGuard在各种数据集上均有较高的准确率，域内准确率高，虚警率低。我们的域内AUC高达0.98，虚警率低至0.04。即使当训练集与测试集差别较大时，跨库AUC仍然能够达到0.74。而以Face X-ray为例，该方法跨库AUC仅为0.65，与之相比，我们的泛化性优势非常明显，检测更加精准。

> P19 P20

我再来介绍一下LiteGuard的创新点。LiteGuard在多个方面都进行了创新。首先，我们采用了通过残差帧捕获时序特征的方法。这种方法能够捕捉到视频中细微的动态不一致性，而且计算复杂度极低，这对于轻量化部署至关重要。其次，我们运用了多样化的数据增强手段 ，包括空间数据增强和时序数据增强，其中空间数据增强包括水平翻转，颜色抖动，高斯模糊等，而时序数据增强则包括随机帧跳跃，帧重复等。这些数据增强手段能够有效地提高模型在面对不同伪造方法和质量时的鲁棒性和泛化能力。再者，我们采用了轻量级预训练模型EfficientFormerV2 ，这为模型的小体积和高效率奠定了基础。最后，我们在数据集方面也进行了创新 。相比于常见的深度伪造数据集FF++与Celeb-DF-v2等相比，我们的数据集不仅具有较高的亚洲人脸样本占比，而且伪造方法多样，伪造质量高，这使得模型的泛化能力得到了进一步的提高。

> P21 

最后，我们来对LiteGuard进行一个简单的演示。

> 演示过程

展示过程。。。

> 结语

LiteGuard的诞生，旨在为用户提供一个可靠、高效、安全的深度伪造检测解决方案。我们相信，通过LiteGuard，能够有效应对深度伪造技术带来的挑战，保护个人隐私和信息安全。感谢(大家)您的聆听！谢谢！