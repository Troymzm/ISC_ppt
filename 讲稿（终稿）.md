# 讲稿（终稿）

> P1 

尊敬的各位评委老师们，大家上午好！非常荣幸今天能在这里向大家介绍我们的作品——LiteGuard，一个基于单帧图像与时序残差分析的高效端侧深伪检测APP。

> P2

我会从以下几个方面来介绍我们的作品：包括背景介绍、系统架构、作品实现、核心优势、作品创新点以及作品的展示。

> P3 P4

首先，我们来回顾一下深度伪造技术的发展历程。早期，应用于电影中的面部融合特效，为深度伪造奠定了概念基础。2017年末，一位名为“deepfakes”的Reddit用户开始发布利用深度学习算法合成的名人换脸视频，使得“Deepfake”（深度伪造）这一术语迅速进入公众视野。在此之后，各种开源深度伪造工具如DeepFaceLab、FaceSwap等相继出现。随着深度学习技术的发展，尤其是生成对抗网络（GANs）的广泛应用，深度伪造技术得到了进一步的提升。如今，深度伪造不仅限于面部替换，还扩展到语音合成、全身动作捕捉等多个领域。

> P5

然而，深度伪造技术生成的高度逼真的虚假视频和图像，已经远超简单的数字篡改，达到了肉眼难辨的程度，可以被用于大规模散布谣言，甚至实施复杂的金融诈骗。例如香港1.2亿港元深度伪造诈骗案以及通过深度伪造技术伪造乌克兰总统泽连斯基的投降视频来误导公众的事件，都显示了深度伪造技术的潜在危害。

> P6

面对深度伪造技术带来的诸多挑战，国家网信办开展了“清朗·整治AI技术滥用”的专项行动，重点打击利用AI技术进行换脸、合成声音以及生成虚假内容的乱象。由此我们可以看到，对深度伪造技术的检测和治理，已经成为当前一个非常重要的需求。

> P7

目前主流的深度伪造检测方案大多采用图片级检测，虽然它们在域内检测准确率较高，但由于依赖特定的伪造方法，导致跨库泛化性差，虚警率高，严重影响了用户体验。并且，大多数方案都采取了云端部署的方式，这不仅增加了用户隐私泄露的风险，还需要消耗大量的计算资源。而在实时视频通话等涉及到最高级的隐私场景中，云端部署显然并不适用。为此，端侧部署的深度伪造检测技术显得尤为重要。但目前主流深伪检测模型普遍参数量较大，无法在计算资源受限的端侧进行部署。部分研究尝试通过模型剪枝、量化等方式实现模型轻量化，但这往往会牺牲模型的检测性能和泛化能力。

> P8

而我们开发的LiteGuard，刚好解决了上述难题。首先，我们通过使用轻量化预训练模型EfficientFormerV2和时序帧间残差分析的方法，成功将模型参数量大幅度压缩，既满足端侧部署要求，又保持较高的准确率与泛化能力。在此基础上，我们成功实现了端侧部署，为业内首个视频级端侧深伪检测方案。我们的模型完全本地化，确保了用户隐私安全，并能够在视频通话场景中提供实时、低延迟、低虚警率的深度伪造检测服务。

> P9 P10

接下来，我将为大家介绍LiteGuard的系统架构。我们的APP主要分为Flutter层和Android层两部分。Flutter层主要包括用户界面模块、状态管理模块和通信模块，它处理用户的输入并显示检测结果。Android层是核心的检测部分，包含预处理模块、图片检测模块和视频检测模块。其中图片检测模块采用基于EfficientFormerV2的单帧图片检测模型，而视频检测模块则采用了基于EfficientnetB0的时序残差分析模型。我们的深伪检测数据集则涵盖了多种伪造方法，并具有较高的亚洲人脸占比，用于训练满足国内用户需求，且具有鲁棒性和泛化性的深伪检测模型。

> P11

再来介绍一下作品实现部分，我们的LiteGuard的实现主要包括帧级空间检测和时序残差检测两部分内容的实现。

> P12

帧级空间检测方面，我们采用了全监督二分类的学习范式。首先我们借助人脸对齐模块  RetinaFace，自动裁剪出人脸区域，确保模型能够聚焦于伪影集中出现的区域。随后对裁剪后的人脸做了多种空间数据增强，比如常见的高斯模糊、压缩、颜色扰动等，以提升模型在复杂环境下的鲁棒性。我们选用EfficientFormerV2 作为轻量级特征提取器，该模型结合了 CNN 对局部细节的强感知能力与 Attention 对全局语义信息的建模优势。其中，CNN能够关注图像中局部细节的伪影区域，而 Attention 则有助于建模图像上下文中的伪造关系。我们进一步通过跨库混合微调策略提高模型在不同数据源上的泛化能力。

> P13

时序残差检测方面。首先，模型接收帧序列的输入；接着，对相邻两帧转为张量后进行残差计算，通过帧间差分来捕获视频中的时间不一致性；然后，对残差进行展平处理后输入到EfficientNet-B0模型提取残差空间特征；提取的特征再经过全局平均池化；最后，通过一个分类头输出预测结果和置信概率，从而判断视频是否为伪造。这种方法的优点在于其不仅能够捕捉到深度伪造视频中普遍存在的时间不一致性问题，提高模型泛化能力，还可以大幅度降低模型参数量，使其适合在端侧设备上运行。

> P14 

再来看一下LiteGuard的核心优势，我们的核心优势主要体现在三个方面：模型轻量化、本地化部署、以及强大的泛化能力。

> P15

首先是模型轻量化 。我们的单帧图片检测模型参数量为1千两百万左右，模型大小仅为47.03 MB。时序残差分析模型的参数量为480万左右，模型大小仅为18.43 MB。与中科院自动化研究所团队开发的开源Deepfake检测模型Deepfake Defenders（模型大小338 MB）相比，LiteGuard的模型尺寸大幅缩小，更适合在计算资源受限的端侧进行部署。

> P16

其次是端侧部署 。LiteGuard的模型完全本地化，用户检测所提供的所有的人脸数据都存储在本地，不会上传至云端。这意味着用户无需担心数据泄露的风险。此外，LiteGuard可以实现即时检测，由于无需网络传输，可以在视频通话或直播中实现实时低延迟的深度伪造识别。这与Sensity等知名Deepfake检测工具形成鲜明对比，Sensity通常需要将数据上传至云端，并且会受到网络带宽的影响以及产生巨大的服务器计算资源开销。

> P17

最后是强大的泛化能力 。LiteGuard在多种数据集上均表现有较高的准确率，域内准确率高，虚警率低。我们的域内AUC高达0.98，虚警率低至0.04。即使当训练集与测试集差别较大时，跨库AUC仍然能够达到0.74。而以Face X-ray为例，该方法跨库AUC仅为0.65，与之相比，我们的泛化性优势非常明显，检测更加精准。

> P18 P19

我再来介绍一下LiteGuard的创新点。LiteGuard在多个方面都进行了创新。首先，我们使用了多样化的数据增强方式 ，包括空间数据增强和时序数据增强，其中空间数据增强包括水平翻转，颜色抖动，高斯模糊等，而时序数据增强则包括随机帧跳跃，帧重复等。这些数据增强手段能够有效地提高模型在面对不同伪造方法和质量时的鲁棒性和泛化能力。并且，我们采用了混合训练策略，提高了数据集中亚洲人脸样本的占比，更加符合国内用户检测需求，并且大幅度降低了虚警率。

> P20 

其次，我们使用了预训练模型EfficientFormerV2及帧间残差分析的方法，使得模型更加轻量化，有效的提高了检测效率，更加适合在计算资源受限的端侧进行部署。最后，我们通过便捷化的端侧开发提高产品应用性，LiteGuard APP是业内首个视频级端侧深伪检测方案，已成功在Android平台上实现了端侧部署，普通用户可以无需联网，直接在手机上使用便捷的深度伪造检测功能。

> P21

最后，我们来对LiteGuard进行一个简单的演示。

> 演示过程

展示过程。。。

> 结语

LiteGuard的诞生，旨在为用户提供一个可靠、高效、安全的深度伪造检测解决方案。我们相信，通过LiteGuard，能够有效应对深度伪造技术带来的挑战，保护个人隐私和信息安全。感谢(大家)您的聆听！谢谢！